<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>其它排错 on Kubernetes 实践指南</title>
    <link>https://k8s.imroc.io/troubleshooting/problems/others/</link>
    <description>Recent content in 其它排错 on Kubernetes 实践指南</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    
	<atom:link href="https://k8s.imroc.io/troubleshooting/problems/others/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Job 无法被删除</title>
      <link>https://k8s.imroc.io/troubleshooting/problems/others/job-cannot-delete/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://k8s.imroc.io/troubleshooting/problems/others/job-cannot-delete/</guid>
      <description>原因  可能是 k8s 的一个bug: https://github.com/kubernetes/kubernetes/issues/43168 本质上是脏数据问题，Running+Succeed != 期望Completions 数量，低版本 kubectl 不容忍，delete job 的时候打开debug(加-v=8)，会看到kubectl不断在重试，直到达到timeout时间。新版kubectl会容忍这些，删除job时会删除关联的pod  解决方法  升级 kubectl 版本，1.12 以上 低版本 kubectl 删除 job 时带 --cascade=false 参数(如果job关联的pod没删完，加这个参数不会删除关联的pod)  kubectl delete job --cascade=false &amp;lt;job name&amp;gt; </description>
    </item>
    
    <item>
      <title>kubectl 执行 exec 或 logs 失败</title>
      <link>https://k8s.imroc.io/troubleshooting/problems/others/kubectl-exec-or-logs-failed/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://k8s.imroc.io/troubleshooting/problems/others/kubectl-exec-or-logs-failed/</guid>
      <description>通常是 apiserver &amp;ndash;&amp;gt; kubelet:10250 之间的网络不通，10250 是 kubelet 提供接口的端口，kubectl exec 和 kubectl logs 的原理就是 apiserver 调 kubelet，kubelet 再调运行时 (比如 dockerd) 来实现的，所以要保证 kubelet 10250 端口对 apiserver 放通。检查防火墙、iptables 规则是否对 10250 端口或某些 IP 进行了拦截。</description>
    </item>
    
    <item>
      <title>内核软死锁</title>
      <link>https://k8s.imroc.io/troubleshooting/problems/others/kernel-solft-lockup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://k8s.imroc.io/troubleshooting/problems/others/kernel-solft-lockup/</guid>
      <description>内核报错 Oct 14 15:13:05 VM_1_6_centos kernel: NMI watchdog: BUG: soft lockup - CPU#5 stuck for 22s! [runc:[1:CHILD]:2274] 原因 发生这个报错通常是内核繁忙 (扫描、释放或分配大量对象)，分不出时间片给用户态进程导致的，也伴随着高负载，如果负载降低报错则会消失。
什么情况下会导致内核繁忙  短时间内创建大量进程 (可能是业务需要，也可能是业务bug或用法不正确导致创建大量进程)  参考资料  What are all these &amp;ldquo;Bug: soft lockup&amp;rdquo; messages about : https://www.suse.com/support/kb/doc/?id=7017652  </description>
    </item>
    
  </channel>
</rss>