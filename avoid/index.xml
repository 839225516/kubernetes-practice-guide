<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>避坑指南 on Kubernetes 实践指南</title>
    <link>https://k8s.imroc.io/avoid/</link>
    <description>Recent content in 避坑指南 on Kubernetes 实践指南</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Sat, 09 May 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://k8s.imroc.io/avoid/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>.Net Core 配置文件在Kubernetes中无法热加载</title>
      <link>https://k8s.imroc.io/avoid/dotnet-configuration-auto-reload/</link>
      <pubDate>Sat, 09 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://k8s.imroc.io/avoid/dotnet-configuration-auto-reload/</guid>
      <description></description>
    </item>
    
    <item>
      <title>cgroup 泄露</title>
      <link>https://k8s.imroc.io/avoid/cgroup-leaking/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://k8s.imroc.io/avoid/cgroup-leaking/</guid>
      <description>内核 Bug memcg 是 Linux 内核中用于管理 cgroup 内存的模块，整个生命周期应该是跟随 cgroup 的，但是在低版本内核中(已知3.10)，一旦给某个 memory cgroup 开启 kmem accounting 中的 memory.kmem.limit_in_bytes 就可能会导致不能彻底删除 memcg 和对应的 cssid，也就是说应用即使已经删除了 cgroup (/sys/fs/cgroup/memory 下对应的 cgroup 目录已经删除), 但在内核中没有释放 cssid，导致内核认为的 cgroup 的数量实际数量不一致，我们也无法得知内核认为的 cgroup 数量是多少。
关于 cgroup kernel memory，在 kernel.org 中有如下描述：
2.7 Kernel Memory Extension (CONFIG_MEMCG_KMEM) ----------------------------------------------- With the Kernel memory extension, the Memory Controller is able to limit the amount of kernel memory used by the system. Kernel memory is fundamentally different than user memory, since it can&#39;t be swapped out, which makes it possible to DoS the system by consuming too much of this precious resource.</description>
    </item>
    
    <item>
      <title>conntrack 冲突导致丢包</title>
      <link>https://k8s.imroc.io/avoid/conntrack-conflict/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://k8s.imroc.io/avoid/conntrack-conflict/</guid>
      <description>TODO</description>
    </item>
    
    <item>
      <title>tcp tw recycle 引发丢包</title>
      <link>https://k8s.imroc.io/avoid/tcp_tw_recycle-causes-packet-loss/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://k8s.imroc.io/avoid/tcp_tw_recycle-causes-packet-loss/</guid>
      <description>tcp_tw_recycle 这个内核参数用来快速回收 TIME_WAIT 连接，不过如果在 NAT 环境下会引发问题。
RFC1323 中有如下一段描述：
An additional mechanism could be added to the TCP, a per-host cache of the last timestamp received from any connection. This value could then be used in the PAWS mechanism to reject old duplicate segments from earlier incarnations of the connection, if the timestamp clock can be guaranteed to have ticked at least once since the old connection was open. This would require that the TIME-WAIT delay plus the RTT together must be at least one tick of the sender’s timestamp clock.</description>
    </item>
    
    <item>
      <title>使用 NodeLocal DNS (缓存)</title>
      <link>https://k8s.imroc.io/avoid/nodelocal-dns/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://k8s.imroc.io/avoid/nodelocal-dns/</guid>
      <description>为什么需要本地 DNS 缓存   减轻集群 DNS 解析压力，提高 DNS 性能
  避免 netfilter 做 DNAT 导致 conntrack 冲突引发 DNS 5 秒延时
 镜像底层库 DNS 解析行为默认使用 UDP 在同一个 socket 并发 A 和 AAAA 记录请求，由于 UDP 无状态，两个请求可能会并发创建 conntrack 表项，如果最终 DNAT 成同一个集群 DNS 的 Pod IP 就会导致 conntrack 冲突，由于 conntrack 的创建和插入是不加锁的，最终后面插入的 conntrack 表项就会被丢弃，从而请求超时，默认 5s 后重试，造成现象就是 DNS 5 秒延时; 底层库是 glibc 的容器镜像可以通过配 resolv.conf 参数来控制 DNS 解析行为，不用 TCP 或者避免相同五元组并发(使用串行解析 A 和 AAAA 避免并发或者使用不同 socket 发请求避免相同源端口)，但像基于 alpine 镜像的容器由于底层库是 musl libc，不支持这些 resolv.</description>
    </item>
    
    <item>
      <title>使用 oom-guard 在用户态处理 cgroup OOM</title>
      <link>https://k8s.imroc.io/avoid/handle-cgroup-oom-in-userspace-with-oom-guard/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://k8s.imroc.io/avoid/handle-cgroup-oom-in-userspace-with-oom-guard/</guid>
      <description>背景 由于 linux 内核对 cgroup OOM 的处理，存在很多 bug，经常有由于频繁 cgroup OOM 导致节点故障(卡死， 重启， 进程异常但无法杀死)，于是 TKE 团队开发了 oom-guard，在用户态处理 cgroup OOM 规避了内核 bug。
原理 核心思想是在发生内核 cgroup OOM kill 之前，在用户空间杀掉超限的容器， 减少走到内核 cgroup 内存回收失败后的代码分支从而触发各种内核故障的机会。
threshold notify 参考文档: https://lwn.net/Articles/529927/
oom-guard 会给 memory cgroup 设置 threshold notify， 接受内核的通知。
以一个例子来说明阀值计算通知原理: 一个 pod 设置的 memory limit 是 1000M， oom-guard 会根据配置参数计算出 margin:
margin = 1000M * margin_ratio = 20M // 缺省margin_ratio是0.02 margin 最小不小于 mim_margin(缺省1M)， 最大不大于 max_margin(缺省为30M)。如果超出范围，则取 mim_margin 或 max_margin。计算 threshold = limit - margin ，也就是 1000M - 20M = 980M，把 980M 作为阈值设置给内核。当这个 pod 的内存使用量达到 980M 时， oom-guard 会收到内核的通知。</description>
    </item>
    
    <item>
      <title>解决长连接服务扩容失效</title>
      <link>https://k8s.imroc.io/avoid/scale-keepalive-service/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://k8s.imroc.io/avoid/scale-keepalive-service/</guid>
      <description>在现网运营中，有很多场景为了提高效率，一般都采用建立长连接的方式来请求。我们发现在客户端以长连接请求服务端的场景下，K8S的自动扩容会失效。原因是客户端长连接一直保留在老的Pod容器中，新扩容的Pod没有新的连接过来，导致K8S按照步长扩容第一批Pod之后就停止了扩容操作，而且新扩容的Pod没能承载请求，进而出现服务过载的情况，自动扩容失去了意义。
对长连接扩容失效的问题，我们的解决方法是将长连接转换为短连接。我们参考了 nginx keepalive 的设计，nginx 中 keepalive_requests 这个配置项设定了一个TCP连接能处理的最大请求数，达到设定值(比如1000)之后服务端会在 http 的 Header 头标记 “Connection:close”，通知客户端处理完当前的请求后关闭连接，新的请求需要重新建立TCP连接，所以这个过程中不会出现请求失败，同时又达到了将长连接按需转换为短连接的目的。通过这个办法客户端和云K8S服务端处理完一批请求后不断的更新TCP连接，自动扩容的新Pod能接收到新的连接请求，从而解决了自动扩容失效的问题。
由于Golang并没有提供方法可以获取到每个连接处理过的请求数，我们重写了 net.Listener 和 net.Conn，注入请求计数器，对每个连接处理的请求做计数，并通过 net.Conn.LocalAddr() 获得计数值，判断达到阈值 1000 后在返回的 Header 中插入 “Connection:close” 通知客户端关闭连接，重新建立连接来发起请求。以上处理逻辑用 Golang 实现示例代码如下：
package main import ( &amp;#34;net&amp;#34; &amp;#34;github.com/gin-gonic/gin&amp;#34; &amp;#34;net/http&amp;#34; ) // 重新定义net.Listener type counterListener struct { net.Listener } // 重写net.Listener.Accept(),对接收到的连接注入请求计数器 func (c *counterListener) Accept() (net.Conn, error) { conn, err := c.Listener.Accept() if err != nil { return nil, err } return &amp;amp;counterConn{Conn: conn}, nil } // 定义计数器counter和计数方法Increment() type counter int func (c *counter) Increment() int { *c++ return int(*c) } // 重新定义net.</description>
    </item>
    
  </channel>
</rss>